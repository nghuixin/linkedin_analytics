{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4f82dedb-941f-40e5-85e2-eaf919ece541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pygwalker as pyg\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58c3e93b-4fbe-4fc0-a0c3-f0049795f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01f83c8d-0e29-4d49-a153-168231b49f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4228 entries, 0 to 4227\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   First Name       4159 non-null   object\n",
      " 1   Last Name        4159 non-null   object\n",
      " 2   URL              4159 non-null   object\n",
      " 3   Email Address    59 non-null     object\n",
      " 4   Company          4098 non-null   object\n",
      " 5   Position         4099 non-null   object\n",
      " 6   Connected On     4228 non-null   object\n",
      " 7   Connected Year   4228 non-null   int32 \n",
      " 8   Connected Month  4228 non-null   int32 \n",
      "dtypes: int32(2), object(7)\n",
      "memory usage: 264.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Connections.csv', skiprows = 3)\n",
    "df['Connected Year'] = pd.to_datetime(df['Connected On']).dt.year\n",
    "df['Connected Month'] = pd.to_datetime(df['Connected On']).dt.month\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42f58e-45d0-4caa-a56e-36fb8e7fdbd4",
   "metadata": {},
   "source": [
    "Interactive data exploration with pygwalker library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee43c3ed-7660-4286-b624-1f4c90b2bc6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf946d6a664e43acad45238ce6e72029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(HTML(value='\\n<div id=\"ifr-pyg-0006213f0d81b4a1BY3WgaXhGN9l4psf\" style=\"height: auto\">\\n    <heaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    window.addEventListener(\"message\", function(event) {\n",
       "        const backgroundMap = {\n",
       "            \"dark\": \"hsl(240 10% 3.9%)\",\n",
       "            \"light\": \"hsl(0 0 100%)\",\n",
       "        };\n",
       "        const colorMap = {\n",
       "            \"dark\": \"hsl(0 0% 98%)\",\n",
       "            \"light\": \"hsl(240 10% 3.9%)\",\n",
       "        };\n",
       "        if (event.data.action === \"changeAppearance\" && event.data.gid === \"0006213f0d81b4a1BY3WgaXhGN9l4psf\") {\n",
       "            var iframe = document.getElementById(\"gwalker-0006213f0d81b4a1BY3WgaXhGN9l4psf\");\n",
       "            iframe.style.background  = backgroundMap[event.data.appearance];\n",
       "            iframe.style.color = colorMap[event.data.appearance];\n",
       "        }\n",
       "    });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyg.walk(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047a9db-f831-4342-ad70-2c07c6a37f3d",
   "metadata": {},
   "source": [
    "### Top 15 Job titles of connections made in 2016-2018, 2024, and across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb2dad-0dcf-4032-9bec-f99a1378b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and get the top 15 positions for each plot\n",
    "transition1 = df.loc[df['Connected Year'].isin([2016, 2017, 2018])]['Position'].value_counts().head(15)\n",
    "transition2 = df.loc[df['Connected Year'].isin([2023, 2024])]['Position'].value_counts().head(15)\n",
    "all_years = df['Position'].value_counts().head(15)\n",
    "\n",
    "# Create a figure with 3 subplots in a row\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Plot 1\n",
    "sns.barplot(x=transition1.index, y=transition1.values, ax=axs[0])\n",
    "axs[0].set_title('Years 2016-2018')\n",
    "axs[0].set_xlabel('Position')\n",
    "axs[0].set_ylabel('Counts')\n",
    "axs[0].tick_params(axis='x', rotation=90)\n",
    "axs[0].set_ylim([0, 80])\n",
    "# Plot 2\n",
    "sns.barplot(x=transition2.index, y=transition2.values, ax=axs[1])\n",
    "axs[1].set_title('Year 2024')\n",
    "axs[1].set_xlabel('Position')\n",
    "axs[1].set_ylabel('Counts')\n",
    "axs[1].tick_params(axis='x', rotation=90)\n",
    "axs[1].set_ylim([0, 80])\n",
    "# Plot 3\n",
    "sns.barplot(x=all_years.index, y=all_years.values, ax=axs[2])\n",
    "axs[2].set_title('Years 2011-2024')\n",
    "axs[2].set_xlabel('Position')\n",
    "axs[2].set_ylabel('Counts')\n",
    "axs[2].tick_params(axis='x', rotation=90)\n",
    "axs[2].set_ylim([0, 80])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca260a-c87f-4766-a9e3-ab9bd4ad9403",
   "metadata": {},
   "source": [
    "### Top 15 Companies connected with across Years 2016-2018, 2024, and across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbb4c8-d2c7-41c8-a2a9-8f5d87dfcdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and get the top 15 positions for each plot\n",
    "transition1 = df.loc[df['Connected Year'].isin([2016, 2017, 2018])]['Company'].value_counts().head(15)\n",
    "transition2 = df.loc[df['Connected Year'].isin([2023, 2024])]['Company'].value_counts().head(15)\n",
    "all_years = df['Company'].value_counts().head(15)\n",
    "\n",
    "# Create a figure with 3 subplots in a row\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Plot 1\n",
    "sns.barplot(x=transition1.index, y=transition1.values, ax=axs[0])\n",
    "axs[0].set_title('Years 2016-2018')\n",
    "axs[0].set_xlabel('Company')\n",
    "axs[0].set_ylabel('Count')\n",
    "axs[0].tick_params(axis='x', rotation=90)\n",
    "axs[0].set_ylim([0, 50])\n",
    "\n",
    "# Plot 2\n",
    "sns.barplot(x=transition2.index, y=transition2.values, ax=axs[1])\n",
    "axs[1].set_title('Year 2024')\n",
    "axs[1].set_xlabel('Company')\n",
    "axs[1].set_ylabel('Count')\n",
    "axs[1].tick_params(axis='x', rotation=90)\n",
    "axs[1].set_ylim([0, 50])\n",
    "\n",
    "# Plot 3\n",
    "sns.barplot(x=all_years.index, y=all_years.values, ax=axs[2])\n",
    "axs[2].set_title('Years 2011-2024')\n",
    "axs[2].set_xlabel('Company')\n",
    "axs[2].set_ylabel('Count')\n",
    "axs[2].tick_params(axis='x', rotation=90)\n",
    "axs[2].set_ylim([0, 50])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93813a-23cb-46ec-8264-c90ee1114aaa",
   "metadata": {},
   "source": [
    "### Historical Overlap of Top 20 Companies: 2016-2018 and 2024 vs. All-Time Patterns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1413a-1c00-4201-b938-3103f6d32dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "companies_2016_2018 = set(df.loc[df['Connected Year'].isin([2016, 2017, 2018])]['Company'].value_counts().head(20).index)\n",
    "companies_2024 = set(df.loc[df['Connected Year'].isin([2023, 2024])]['Company'].value_counts().head(20).index)\n",
    "all_companies = set(df['Company'].value_counts().head(20).index)\n",
    "\n",
    "# Find overlapping companies between 2024 and all years\n",
    "all_years_overlap_with_2024 = all_companies.intersection(companies_2024)\n",
    "print(\"Top companies represented in both 2024 and across all years\", all_years_overlap_with_2024)\n",
    "\n",
    "# Find overlapping companies between 2016-2018 and all years\n",
    "all_years_overlap_with_20161718 = all_companies.intersection(companies_2016_2018)\n",
    "print(\"Top companies represented in 2016-2018 and across all years\", all_years_overlap_with_20161718)\n",
    "\n",
    "# Find companies in 2016-2018 but not in all years\n",
    "unique_2016_2018 = companies_2016_2018.difference(all_companies)\n",
    "print(\"Top companies represented only in 2016-2018, but not across all years\", unique_2016_2018)\n",
    "\n",
    "# Find companies in 2024 but not all years\n",
    "unique_2024 = companies_2024.difference(all_companies)\n",
    "print(\"Top companies represented in 2024 but not across all years\", unique_2024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500374a0-fe5c-4b4f-8870-0bc200405423",
   "metadata": {},
   "source": [
    "### Number of connections all-time - count and percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f2817-5a84-4b74-8937-953b17798472",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Plot 1: Count of 'Connected Year'\n",
    "sns.countplot(x=df['Connected Year'], ax=axs[0])\n",
    "axs[0].set_title('Count of Connected Years')\n",
    "axs[0].set_xlabel('Connected Year')\n",
    "axs[0].set_ylabel('Count')\n",
    "axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 2: Proportion of 'Connected Year'\n",
    "sns.barplot(x=df['Connected Year'].value_counts().index, \n",
    "            y=df['Connected Year'].value_counts().values / df['Connected Year'].value_counts().sum()*100, ax=axs[1])\n",
    "axs[1].set_title('Proportion of Connected Years')\n",
    "axs[1].set_xlabel('Connected Year')\n",
    "axs[1].set_ylabel('Proportion')\n",
    "axs[1].tick_params(axis='x', rotation=45)\n",
    "plt.axhline(y = 10, color = 'r', linestyle = '-') \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d75111-93a7-4f11-a502-5b4c9f7c8a27",
   "metadata": {},
   "source": [
    "### Number of Connections made by month across Years 2017, 2018 and Year 2024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac227db-e933-4cd2-9b74-f7c038e12ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Connected Month'] =  pd.to_datetime(df['Connected On']).dt.month\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for year in [2017, 2018, 2024]:\n",
    "    yearly_data = df[df['Connected Year'] == year]\n",
    "    month_counts = yearly_data['Connected Month'].value_counts().sort_index()  # Ensure months are sorted\n",
    "    plt.plot(month_counts.index, month_counts.values, marker='x', label=str(year))\n",
    "\n",
    "plt.title('Number of Connections by Month across 2017, 2018 and 2024')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Connections')\n",
    "plt.xticks(range(1, 13))  # Set x-axis ticks to represent months 1-12\n",
    "plt.legend(title='Year')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b616e-944a-4c60-9389-078184d06443",
   "metadata": {},
   "source": [
    "### Word Cloud of Job Title of Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d6271-40a4-4b51-8a76-a49ea2174fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "for year in [2017, 2024]:\n",
    "    # Filter the DataFrame for the current year in the loop\n",
    "    yearly_data = df[df['Connected Year'] == year]\n",
    "    \n",
    "    # Assuming 'Position' is the column containing the text data\n",
    "    text = \" \".join(yearly_data['Position'].astype(str))\n",
    "    \n",
    "    # Remove all numbers and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    \n",
    "    # Create and generate a word cloud image\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "    \n",
    "    # Display the generated image with the year as the title\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f\"Job Title Word Cloud for {year}\")\n",
    "    plt.axis(\"off\")  # Turn off the axis\n",
    "    plt.show()  # Display the word cloud image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d7f96-69ab-4dbc-a7d2-dba72f0f1881",
   "metadata": {},
   "source": [
    "### Job title of connections made in July and August 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90a74b-1f75-4a0b-8e53-5cc905cf46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for the year 2024 and month 8\n",
    "yearly_data = df[(df['Connected Year'] == 2024) & (df['Connected Month'].isin([7, 8]))]\n",
    "\n",
    "text = \" \".join(yearly_data['Position'].astype(str))\n",
    "\n",
    "# Remove all numbers and punctuation\n",
    "text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "\n",
    "# Create and generate a word cloud image\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "fig = plt.gcf()\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")  # Turn off the axis\n",
    "plt.show()  # Display the word cloud image\n",
    "#fig.savefig('wc_august2024.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de91703b-9934-4f93-88f4-6b980e00859d",
   "metadata": {},
   "source": [
    "## Word clustering using NLTK library vs. a pre-trained BEERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494dbcbb-f434-4b38-8185-97a7abd47b38",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "- Convert the text into a sparse matrix of token counts using weighted token counts\n",
    "- Create fixed size vocab based on corpus\n",
    "- Each document is represented as a vector of size equal to the vocab\n",
    "- Each word is treated independently of others, features are based on frequency of terms\n",
    "- Used for document classification, key word extraction\n",
    "- Might be less accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d05fbf-fa94-4d9d-971c-df3371fd613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df.loc[:, 'Position'] = df['Position'].fillna('')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text =  re.sub(r'\\d+', '', text)   # replace digits with empty sr\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text).lower() # replace punctuation with space and lowercase all text\n",
    "    stop_words = set(stopwords.words('english')) # remove stop wrods\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['cleaned_job_titles'] = df['Position'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037ea3e-b4a5-4622-8f8b-2823fca59feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the cleaned job titles\n",
    "X = vectorizer.fit_transform(df['cleaned_job_titles']) \n",
    "\n",
    "# Determine the optimal number of clusters using the silhouette score\n",
    "range_n_clusters = list(range(2, 10))\n",
    "best_n_clusters = 2\n",
    "best_silhouette_score = -1\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    if silhouette_avg > best_silhouette_score:\n",
    "        best_n_clusters = n_clusters\n",
    "        best_silhouette_score = silhouette_avg\n",
    "\n",
    "# Fit the best KMeans model\n",
    "kmeans = KMeans(n_clusters=best_n_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "print(best_n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7b8f1-fb8c-498e-9155-a12876f5fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=df['cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Job Title Clusters')\n",
    "# Add legend to show cluster labels\n",
    "\n",
    "# Calculate and plot cluster centroids\n",
    "unique_clusters = np.unique(yearly_data['cluster'])\n",
    "for cluster in unique_clusters:\n",
    "    # Get all points in the current cluster\n",
    "    points_in_cluster = X_reduced[df['cluster'] == cluster]\n",
    "    # Calculate the centroid\n",
    "    centroid = points_in_cluster.mean(axis=0)\n",
    "    # Annotate the cluster number at the centroid\n",
    "    plt.text(centroid[0], centroid[1], str(cluster), fontsize=15, fontweight='bold', ha='center', va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35addfd-0c5b-403f-8fee-d840559db379",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = df['cluster'].value_counts()\n",
    "for c in cluster_count.index:\n",
    "    # Filter the DataFrame for the current year in the loop\n",
    "    temp = yearly_data[df['cluster'] == c]\n",
    "    \n",
    "    # Assuming 'Position' is the column containing the text data\n",
    "    text = \" \".join(temp['cleaned_job_titles'].astype(str))\n",
    "    \n",
    "    # Remove all numbers and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    \n",
    "    # Create and generate a word cloud image\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "    count = df[c]\n",
    "    # Display the generated image with the year as the title\n",
    "    fig = plt.gcf()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f\"Job Title Word Cloud for Cluster {c}: {count} connections\")\n",
    "    plt.axis(\"off\")  # Turn off the axis\n",
    "    plt.show()  # Display the word cloud image\n",
    "    plt.savefig(f'nltk_clusters_{c}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b700a05-ef12-484e-bbfb-31f0162f8d55",
   "metadata": {},
   "source": [
    "#### Pre-trained BERT \n",
    "- Feature vectors capture information from high dimensions\n",
    "- Can leverage contextual understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5077e-e821-4baf-bfc4-1e542b293c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v2')\n",
    "# https://huggingface.co/sentence-transformers/paraphrase-distilroberta-base-v2\n",
    "# https://medium.com/@abhishekranjandev/building-a-semantic-search-engine-with-machine-learning-and-jupyter-notebooks-fbcb15b538c5\n",
    "\n",
    "X = model.encode(df['cleaned_job_titles'].tolist()) # pre-trained Sentence-BERT model to generate document embeddings\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_n_clusters, random_state=42) # number of clusters determined above = 8\n",
    "df['cluster'] = kmeans.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fe996-5d70-4a62-a4f7-1b348ec3cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=yearly_data['cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Job Title Clusters')\n",
    "# Add legend to show cluster labels\n",
    "# Calculate and plot cluster centroids\n",
    "unique_clusters = np.unique(df['cluster'])\n",
    "for cluster in unique_clusters:\n",
    "    # Get all points in the current cluster\n",
    "    points_in_cluster = X_reduced[df['cluster'] == cluster]\n",
    "    # Calculate the centroid\n",
    "    centroid = points_in_cluster.mean(axis=0)\n",
    "    # Annotate the cluster number at the centroid\n",
    "    plt.text(centroid[0], centroid[1], str(cluster), fontsize=15, fontweight='bold', ha='center', va='center', color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c360e-9f53-4853-9b97-9bcdd0f468ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = df['cluster'].value_counts()\n",
    "cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3516638-f471-46b2-b054-be02a19bdab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = yearly_data['cluster'].value_counts()\n",
    "for c in cluster_count.index:\n",
    "    # Filter the DataFrame for the current year in the loop\n",
    "    temp = df[yearly_data['cluster'] == c]\n",
    "    \n",
    "    # Assuming 'Position' is the column containing the text data\n",
    "    text = \" \".join(temp['cleaned_job_titles'].astype(str))\n",
    "    \n",
    "    # Remove all numbers and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    \n",
    "    # Create and generate a word cloud image\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "    count = cluster_count[c]\n",
    "    # Display the generated image with the year as the title\n",
    "    fig = plt.gcf()\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f\"Job Title Word Cloud for Cluster {c}: {count} connections\")\n",
    "    plt.axis(\"off\")  # Turn off the axis\n",
    "    plt.show()  # Display the word cloud image\n",
    "    plt.savefig(f'bert_clusters_{c}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77838e5c-e7fa-4721-993f-53e0080eb9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
